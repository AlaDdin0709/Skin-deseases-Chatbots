# ‚ö° LLM-Bot - Guide de D√©marrage Rapide (5 minutes)

## üéØ Installation Express

### √âtape 1: Environnement (30 secondes)

```powershell
# Activer l'environnement existant
conda activate rag

# OU cr√©er un nouvel environnement
conda create -n rag python=3.10 -y
conda activate rag
```

### √âtape 2: PyTorch + CUDA (2-3 minutes)

```powershell
cd E:\Chatbots\LLM-Bot
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y
```

### √âtape 3: D√©pendances (1-2 minutes)

```powershell
pip install -r requirements.txt
```

### √âtape 4: Configuration (30 secondes)

```powershell
# Copier template
copy .env.example .env

# √âditer .env avec Notepad
notepad .env

# Ajouter votre token HuggingFace:
# HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxx
```

**Obtenir un token:** https://huggingface.co/settings/tokens

### √âtape 5: V√©rification (15 secondes)

```powershell
python scripts\check_installation.py
```

V√©rifier: ‚úÖ Tous les packages OK, ‚úÖ GPU ready

### √âtape 6: Index FAISS (2-3 minutes)

```powershell
python scripts\build_index.py
```

Attendez: "‚úÖ Index built successfully!"

### √âtape 7: Lancement (10 secondes)

```powershell
python src\app.py
```

Ouvrir: http://localhost:7861

## üéÆ Premier Test

### Option A: Analyse de Sympt√¥mes

1. Onglet **"Analyse de Sympt√¥mes"**
2. Sympt√¥mes: `L√©sion pigment√©e asym√©trique avec bords irr√©guliers et plusieurs couleurs`
3. Dur√©e: `2 mois`
4. ‚úÖ RAG activ√©
5. Cliquer **"Analyser"**

### Option B: Question G√©n√©rale

1. Onglet **"Questions G√©n√©rales"**
2. Question: `Quels sont les crit√®res ABCDE pour le diagnostic de m√©lanome?`
3. ‚úÖ RAG activ√©
4. Cliquer **"Demander"**

## ‚öôÔ∏è Configuration Minimale

### GPU RTX 3050 (4GB VRAM)

Dans `config.yaml`, v√©rifier:

```yaml
models:
  llm:
    quantization:
      load_in_8bit: true        # ESSENTIEL pour 4GB
    max_memory:
      0: "4GB"                  # Limite GPU
      "cpu": "16GB"             # Overflow vers CPU
```

### Param√®tres Recommand√©s

- **Tokens**: 512 (d√©faut)
- **Temp√©rature**: 0.7 (d√©faut)
- **Sources RAG**: 5 (d√©faut)

## üêõ D√©pannage Express

### ‚ùå "CUDA out of memory"

```yaml
# config.yaml - R√©duire limite GPU
max_memory:
  0: "3GB"      # Au lieu de 4GB
```

### ‚ùå "Index not found"

```powershell
python scripts\build_index.py
```

### ‚ùå "HuggingFace token required"

1. https://huggingface.co/settings/tokens ‚Üí Create token
2. `.env` ‚Üí `HF_TOKEN=hf_votre_token`

### ‚ùå "Module not found"

```powershell
pip install -r requirements.txt
```

## üìä Utilisation M√©moire

| Composant | VRAM | RAM |
|-----------|------|-----|
| Flan-T5-XL (8-bit) | ~2.5GB | ~1GB |
| Embeddings (CPU) | 0GB | ~500MB |
| FAISS (CPU) | 0GB | ~200MB |
| **Total** | **~3GB** | **~2GB** |

## ‚úÖ Checklist Rapide

- [ ] Conda env `rag` activ√©
- [ ] PyTorch CUDA 12.1 install√©
- [ ] Toutes d√©pendances install√©es
- [ ] `.env` avec `HF_TOKEN` configur√©
- [ ] `check_installation.py` ‚Üí Tout OK
- [ ] Index FAISS construit
- [ ] App lanc√©e sur port 7861
- [ ] Test de question ‚Üí R√©ponse re√ßue

## üéØ Commandes Essentielles

```powershell
# Activer environnement
conda activate rag

# V√©rifier installation
python scripts\check_installation.py

# Reconstruire index (si keywords chang√©s)
python scripts\build_index.py

# Lancer application
python src\app.py

# Arr√™ter application
Ctrl+C
```

## üìù Diff√©rences avec VLM-Bot

‚úÖ M√™me environnement `rag`  
‚úÖ Pas de conflit de d√©pendances  
‚ùå Pas de VLM (Llava)  
‚ùå Pas de OpenCV  
‚úÖ Texte uniquement (pas d'images)  
‚úÖ Port diff√©rent (7861 vs 7860)

## üöÄ Pr√™t!

Votre LLM-Bot est maintenant op√©rationnel.

**Port**: http://localhost:7861  
**Mode 1**: Analyse de Sympt√¥mes  
**Mode 2**: Questions G√©n√©rales

‚ö†Ô∏è **IMPORTANT**: Usage √©ducatif uniquement. Consultez toujours un professionnel de sant√©.

---

Pour plus de d√©tails: Voir **README.md**
