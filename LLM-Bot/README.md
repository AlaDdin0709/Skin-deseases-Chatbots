# ğŸ¤– LLM-Bot - SystÃ¨me de Q&A Dermatologique

SystÃ¨me de questions/rÃ©ponses dermatologiques basÃ© sur **Google Flan-T5-XL** et **RAG** (Retrieval-Augmented Generation).

## ğŸ¯ FonctionnalitÃ©s

- **LLM**: Google Flan-T5-XL avec quantisation 8-bit (compatible 4GB VRAM)
- **RAG**: Recherche dans la littÃ©rature mÃ©dicale (TimSchopf/medical_abstracts)
- **Interface Gradio**: 2 modes (Analyse de symptÃ´mes + Q&A gÃ©nÃ©ral)
- **Architecture modulaire**: Services LLM, RAG, utilitaires

## ğŸ“‹ PrÃ©requis

- **GPU**: NVIDIA RTX 3050 Laptop (4GB VRAM) ou supÃ©rieur
- **CUDA**: 12.1+ (Driver 591.59+)
- **Python**: 3.10+
- **Conda**: RecommandÃ© pour gestion d'environnement
- **HuggingFace Token**: Requis pour tÃ©lÃ©chargement des modÃ¨les

## ğŸš€ Installation Rapide

### 1. CrÃ©er l'environnement Conda

```powershell
# Utiliser l'environnement 'rag' existant (partagÃ© avec VLM-Bot)
conda activate rag

# OU crÃ©er un nouvel environnement
conda create -n rag python=3.10 -y
conda activate rag
```

### 2. Installer PyTorch avec CUDA 12.1

```powershell
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y
```

### 3. Installer les dÃ©pendances

```powershell
cd E:\Chatbots\LLM-Bot
pip install -r requirements.txt
```

### 4. Configurer l'environnement

```powershell
# Copier le template
copy .env.example .env

# Ã‰diter .env et ajouter votre token HuggingFace
# HF_TOKEN=hf_your_actual_token_here
```

Obtenir un token: https://huggingface.co/settings/tokens

### 5. VÃ©rifier l'installation

```powershell
python scripts\check_installation.py
```

### 6. Construire l'index FAISS

```powershell
python scripts\build_index.py
```

*DurÃ©e: ~2-3 minutes (tÃ©lÃ©charge et indexe les abstracts mÃ©dicaux)*

### 7. Lancer l'application

```powershell
python src\app.py
```

Interface disponible: http://localhost:7861

## ğŸ“ Structure du Projet

```
LLM-Bot/
â”œâ”€â”€ config.yaml              # Configuration centrale
â”œâ”€â”€ requirements.txt         # DÃ©pendances Python
â”œâ”€â”€ .env.example            # Template d'environnement
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py              # Application Gradio
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llm_service.py  # Service Flan-T5-XL
â”‚   â”‚   â””â”€â”€ rag_service.py  # Service RAG + FAISS
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ helpers.py      # Fonctions utilitaires
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_index.py      # Construction index FAISS
â”‚   â””â”€â”€ check_installation.py  # VÃ©rification installation
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ raw/                # DonnÃ©es brutes
    â””â”€â”€ processed/          # Index FAISS
        â””â”€â”€ faiss_index/
```

## âš™ï¸ Configuration

### ModÃ¨le LLM (config.yaml)

```yaml
models:
  llm:
    name: "google/flan-t5-xl"
    quantization:
      load_in_8bit: true        # 8-bit pour 4GB VRAM
      device_map: "auto"
    torch_dtype: "float16"
    max_memory:
      0: "4GB"                  # GPU 0
      "cpu": "16GB"
```

### RAG (config.yaml)

```yaml
rag:
  dataset: "TimSchopf/medical_abstracts"
  chunk_size: 500
  chunk_overlap: 100
  top_k: 5
  index_path: "data/processed/faiss_index"
  keywords:                     # Filtrage par mots-clÃ©s
    skin_cancer: [...]
    benign_lesions: [...]
    # ... 6 catÃ©gories, 80+ termes
```

## ğŸ® Utilisation

### Mode 1: Analyse de SymptÃ´mes

1. Onglet **"Analyse de SymptÃ´mes"**
2. DÃ©crire les symptÃ´mes (ex: "LÃ©sion pigmentÃ©e avec bords irrÃ©guliers")
3. Indiquer la durÃ©e (ex: "3 mois")
4. Activer RAG (recommandÃ©)
5. Cliquer **"Analyser"**

### Mode 2: Questions GÃ©nÃ©rales

1. Onglet **"Questions GÃ©nÃ©rales"**
2. Poser une question (ex: "Quels sont les critÃ¨res ABCDE?")
3. Activer RAG (recommandÃ©)
4. Cliquer **"Demander"**

### ParamÃ¨tres AvancÃ©s

- **Nombre de sources**: 1-10 (dÃ©faut: 5)
- **Tokens de gÃ©nÃ©ration**: 128-1024 (dÃ©faut: 512)
- **TempÃ©rature**: 0.1-1.0 (dÃ©faut: 0.7)

## ğŸ“Š SpÃ©cifications Techniques

### ModÃ¨le LLM

- **Nom**: google/flan-t5-xl
- **Taille**: ~3GB (quantisÃ© 8-bit)
- **VRAM**: ~2.5-3GB lors de l'infÃ©rence
- **Architecture**: T5 (Text-to-Text Transfer Transformer)

### RAG

- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2 (CPU)
- **Vectorstore**: FAISS (CPU, ~200MB)
- **Dataset**: TimSchopf/medical_abstracts (~50k abstracts)
- **Filtrage**: 80+ keywords dermatologiques (6 catÃ©gories)

### Performance

- **Chargement initial**: ~30-60 secondes
- **GÃ©nÃ©ration**: ~5-10 secondes (512 tokens)
- **Recherche RAG**: <1 seconde
- **MÃ©moire GPU**: ~3GB (peak)

## ğŸ”§ DÃ©pendances ClÃ©s

```
torch>=2.0.0               # PyTorch avec CUDA
transformers>=4.36.0       # Hugging Face Transformers
bitsandbytes>=0.41.0       # Quantisation 8-bit
sentencepiece>=0.1.99      # Tokenizer T5
langchain>=0.1.0           # RAG framework
faiss-cpu>=1.7.4           # Recherche vectorielle
sentence-transformers>=2.2.2  # Embeddings
gradio>=4.0.0              # Interface web
```

## ğŸ› DÃ©pannage

### Erreur: "CUDA out of memory"

- RÃ©duire `max_memory["0"]` dans config.yaml (ex: "3GB")
- RÃ©duire `max_new_tokens` (ex: 256)
- Fermer autres applications GPU

### Erreur: "Index not found"

```powershell
python scripts\build_index.py
```

### Erreur: "HuggingFace token required"

1. CrÃ©er un token: https://huggingface.co/settings/tokens
2. Ajouter dans `.env`: `HF_TOKEN=hf_...`

### Erreur: "ModuleNotFoundError"

```powershell
# RÃ©installer dÃ©pendances
pip install -r requirements.txt --force-reinstall
```

### Performance lente

- VÃ©rifier GPU utilisÃ©: `torch.cuda.is_available()`
- Installer CUDA 12.1: `conda install pytorch-cuda=12.1 -c nvidia`

## ğŸ“ Notes Importantes

- **Disclaimer**: Ã€ usage Ã©ducatif uniquement. Consultez toujours un professionnel.
- **Rapports**: SauvegardÃ©s automatiquement (`analysis_YYYYMMDD_HHMMSS.txt`)
- **CompatibilitÃ©**: Environnement `rag` partagÃ© avec VLM-Bot (pas de conflit)

## ğŸ”„ DiffÃ©rences avec VLM-Bot

| FonctionnalitÃ© | LLM-Bot | VLM-Bot |
|---------------|---------|---------|
| ModÃ¨le | Flan-T5-XL (LLM) | Llava-1.5-7B (VLM) |
| EntrÃ©e | Texte uniquement | Image + Texte |
| OpenCV | âŒ Non | âœ… Oui |
| Quantisation | 8-bit | 4-bit |
| VRAM | ~3GB | ~3.5GB |
| Port Gradio | 7861 | 7860 |

## ğŸ“š Ressources

- [Flan-T5 Paper](https://arxiv.org/abs/2210.11416)
- [FAISS Documentation](https://faiss.ai/)
- [Gradio Docs](https://www.gradio.app/docs/)

## ğŸ¤ Contribution

Environnement compatible avec VLM-Bot - utilisez le mÃªme env `rag` pour les deux projets.

---

**Version**: 1.0.0  
**License**: Educational Use Only  
**Contact**: Consultez un dermatologue qualifiÃ© pour tout avis mÃ©dical.
