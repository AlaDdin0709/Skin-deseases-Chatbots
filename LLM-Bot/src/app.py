"""
Application Gradio - LLM-Bot
Interface web pour l'analyse dermatologique bas√©e sur texte (Flan-T5-XL + RAG).
"""

import gradio as gr
import logging
from pathlib import Path
from datetime import datetime

from services.llm_service import LLMService
from services.rag_service import RAGService
from utils.helpers import (
    load_config,
    setup_logging,
    load_environment,
    ensure_directories,
    format_prompt,
    format_medical_prompt
)

# Setup
setup_logging("INFO")
logger = logging.getLogger(__name__)

# Charger configuration et environnement
try:
    load_environment()
    config = load_config()
    ensure_directories(config)
except Exception as e:
    logger.error(f"‚ùå Erreur de configuration: {e}")
    raise

# Initialiser les services globaux
llm_service = None
rag_service = None


def initialize_services():
    """Initialise les services LLM et RAG (lazy loading)."""
    global llm_service, rag_service
    
    if llm_service is None:
        logger.info("üîÑ Initialisation du LLM...")
        llm_service = LLMService(config['models']['llm'])
        llm_service.load_model()
    
    if rag_service is None:
        logger.info("üîÑ Chargement de l'index RAG...")
        rag_service = RAGService(config['rag'])
        index_path = config['rag'].get('index_path', 'data/processed/faiss_index')
        
        if Path(index_path).exists():
            rag_service.load_index(index_path)
        else:
            logger.warning("‚ö†Ô∏è  Index RAG non trouv√©. Construction en cours...")
            rag_service.build_index(save_path=index_path)


def analyze_symptoms(
    symptoms: str,
    duration: str,
    use_rag: bool,
    num_sources: int,
    max_tokens: int,
    temperature: float
):
    """
    Analyse bas√©e sur texte (sympt√¥mes).
    
    Args:
        symptoms: Description des sympt√¥mes
        duration: Dur√©e des sympt√¥mes
        use_rag: Utiliser RAG pour contexte m√©dical
        num_sources: Nombre de sources RAG
        max_tokens: Max tokens √† g√©n√©rer
        temperature: Temp√©rature de sampling
        
    Returns:
        Tuple (sources_text, diagnosis_text)
    """
    if not symptoms or not symptoms.strip():
        return "‚ö†Ô∏è Veuillez d√©crire les sympt√¥mes!", ""
    
    try:
        # Initialiser les services (lazy)
        initialize_services()
        
        # Phase 1: Recherche RAG
        sources_text = ""
        retrieved_context = ""
        
        if use_rag:
            logger.info("üìö Recherche RAG...")
            
            # Construire query √† partir des sympt√¥mes
            query_text = f"{symptoms} {duration}"
            rag_results = rag_service.search(query_text, top_k=int(num_sources))
            
            sources_text = f"**Found {len(rag_results)} relevant medical abstracts:**\n\n"
            
            for i, (doc, score) in enumerate(rag_results, 1):
                sources_text += f"**[Source {i}]** (Relevance: {score:.4f})\n"
                sources_text += f"{doc.page_content}\n"
                sources_text += f"{'-'*80}\n\n"
                retrieved_context += f"\n[Source {i}]:\n{doc.page_content}\n"
        else:
            sources_text = "**RAG d√©sactiv√©** - G√©n√©ration bas√©e uniquement sur les connaissances du LLM.\n"
        
        # Phase 2: Construire le prompt
        if use_rag and retrieved_context:
            prompt = format_medical_prompt(symptoms, duration, retrieved_context)
        else:
            prompt = format_prompt(
                f"Patient symptoms: {symptoms}\nDuration: {duration}",
                "",
                mode="direct"
            )
        
        # Phase 3: G√©n√©ration LLM
        logger.info("ü§ñ G√©n√©ration de l'analyse...")
        diagnosis = llm_service.generate_response(
            prompt=prompt,
            max_new_tokens=int(max_tokens),
            temperature=float(temperature)
        )
        
        # Sauvegarder le rapport
        if use_rag and retrieved_context:
            rag_block = f"RETRIEVED MEDICAL LITERATURE:\n{retrieved_context}\n\n{'='*80}\n"
        else:
            rag_block = ""
        
        report = f"""
DERMATOLOGICAL ANALYSIS REPORT (TEXT-BASED)
{'='*80}
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Model: Flan-T5-XL + RAG

PATIENT INFORMATION:
- Symptoms: {symptoms}
- Duration: {duration}

{rag_block}

PRELIMINARY ASSESSMENT:
{diagnosis}

DISCLAIMER: For research and educational purposes only. NOT a substitute for
professional medical advice, diagnosis, or treatment. Consult a qualified dermatologist.
{'='*80}
"""
        
        filename = f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"‚úÖ Analyse termin√©e. Rapport: {filename}")
        
        return sources_text, diagnosis
        
    except Exception as e:
        logger.error(f"‚ùå Erreur: {e}", exc_info=True)
        import traceback
        error_msg = f"‚ùå Erreur: {str(e)}\n\n{traceback.format_exc()}"
        return error_msg, ""


def answer_question(
    question: str,
    use_rag: bool,
    num_sources: int,
    max_tokens: int,
    temperature: float
):
    """
    R√©pond √† une question m√©dicale g√©n√©rale.
    
    Args:
        question: Question de l'utilisateur
        use_rag: Utiliser RAG
        num_sources: Nombre de sources
        max_tokens: Tokens max
        temperature: Temp√©rature
        
    Returns:
        Tuple (sources_text, answer_text)
    """
    if not question or not question.strip():
        return "‚ö†Ô∏è Veuillez poser une question!", ""
    
    try:
        initialize_services()
        
        # RAG search
        sources_text = ""
        retrieved_context = ""
        
        if use_rag:
            logger.info("üìö Recherche RAG...")
            rag_results = rag_service.search(question, top_k=int(num_sources))
            
            sources_text = f"**Found {len(rag_results)} relevant sources:**\n\n"
            
            for i, (doc, score) in enumerate(rag_results, 1):
                sources_text += f"**[Source {i}]** (Relevance: {score:.4f})\n"
                sources_text += f"{doc.page_content}\n"
                sources_text += f"{'-'*80}\n\n"
                retrieved_context += f"\n[Source {i}]:\n{doc.page_content}\n"
        else:
            sources_text = "**RAG d√©sactiv√©**\n"
        
        # Prompt
        if use_rag and retrieved_context:
            prompt = format_prompt(question, retrieved_context, mode="with_context")
        else:
            prompt = format_prompt(question, "", mode="direct")
        
        # Generate
        logger.info("ü§ñ G√©n√©ration de la r√©ponse...")
        answer = llm_service.generate_response(
            prompt=prompt,
            max_new_tokens=int(max_tokens),
            temperature=float(temperature)
        )
        
        return sources_text, answer
        
    except Exception as e:
        logger.error(f"‚ùå Erreur: {e}", exc_info=True)
        import traceback
        error_msg = f"‚ùå Erreur: {str(e)}\n\n{traceback.format_exc()}"
        return error_msg, ""


# ============================================================================
# Interface Gradio
# ============================================================================

custom_css = """
    .gradio-container {
        max-width: 1400px !important;
    }
    .output-text {
        max-height: 500px;
        overflow-y: auto;
    }
"""

with gr.Blocks(
    title="LLM-Bot - Dermatological Q&A",
) as demo:
    
    gr.Markdown("""
    # ü§ñ LLM-Bot - Syst√®me de Questions/R√©ponses Dermatologiques
    
    **Flan-T5-XL + RAG**
    
    - ü§ñ **LLM**: Google Flan-T5-XL avec quantisation 8-bit
    - üìö **RAG**: Recherche dans la litt√©rature m√©dicale
    - üí¨ **Interface**: Analyse de sympt√¥mes et questions g√©n√©rales
    
    ‚ö†Ô∏è **DISCLAIMER**: Usage √©ducatif uniquement. Consultez toujours un dermatologue.
    """)
    
    with gr.Tabs():
        # ============================================================
        # Tab 1: Analyse de Sympt√¥mes
        # ============================================================
        with gr.Tab("ü©∫ Analyse de Sympt√¥mes"):
            gr.Markdown("### D√©crivez les sympt√¥mes dermatologiques")
            
            with gr.Row():
                with gr.Column(scale=1):
                    symptoms_input = gr.Textbox(
                        label="Sympt√¥mes",
                        placeholder="Ex: L√©sion pigment√©e avec bords irr√©guliers...",
                        lines=5
                    )
                    
                    duration_input = gr.Textbox(
                        label="Dur√©e",
                        placeholder="Ex: 3 mois",
                        lines=1
                    )
                    
                    use_rag_symptoms = gr.Checkbox(
                        value=True,
                        label="‚úÖ Utiliser RAG (Recommand√©)",
                        info="Recherche dans la litt√©rature m√©dicale"
                    )
                    
                    with gr.Accordion("‚öôÔ∏è Param√®tres avanc√©s", open=False):
                        num_sources_symptoms = gr.Slider(
                            1, 10, value=5, step=1,
                            label="Nombre de sources"
                        )
                        max_tokens_symptoms = gr.Slider(
                            128, 1024, value=512, step=64,
                            label="Tokens de g√©n√©ration"
                        )
                        temperature_symptoms = gr.Slider(
                            0.1, 1.0, value=0.7, step=0.1,
                            label="Temp√©rature"
                        )
                    
                    analyze_btn = gr.Button("ü©∫ Analyser", variant="primary", size="lg")
                
                with gr.Column(scale=2):
                    gr.Markdown("### üìä R√©sultats")
                    
                    with gr.Tabs():
                        with gr.Tab("üìö Sources M√©dicales"):
                            sources_output_symptoms = gr.Textbox(
                                label="Litt√©rature r√©cup√©r√©e",
                                lines=12,
                                max_lines=25,
                                elem_classes=["output-text"]
                            )
                        
                        with gr.Tab("üè• Analyse"):
                            diagnosis_output_symptoms = gr.Textbox(
                                label="Analyse pr√©liminaire",
                                lines=12,
                                max_lines=25,
                                elem_classes=["output-text"]
                            )
            
            analyze_btn.click(
                fn=analyze_symptoms,
                inputs=[
                    symptoms_input,
                    duration_input,
                    use_rag_symptoms,
                    num_sources_symptoms,
                    max_tokens_symptoms,
                    temperature_symptoms
                ],
                outputs=[sources_output_symptoms, diagnosis_output_symptoms]
            )
        
        # ============================================================
        # Tab 2: Questions G√©n√©rales
        # ============================================================
        with gr.Tab("‚ùì Questions G√©n√©rales"):
            gr.Markdown("### Posez une question sur la dermatologie")
            
            with gr.Row():
                with gr.Column(scale=1):
                    question_input = gr.Textbox(
                        label="Votre question",
                        placeholder="Ex: Quels sont les crit√®res ABCDE pour le m√©lanome?",
                        lines=4
                    )
                    
                    use_rag_qa = gr.Checkbox(
                        value=True,
                        label="‚úÖ Utiliser RAG (Recommand√©)"
                    )
                    
                    with gr.Accordion("‚öôÔ∏è Param√®tres avanc√©s", open=False):
                        num_sources_qa = gr.Slider(
                            1, 10, value=5, step=1,
                            label="Nombre de sources"
                        )
                        max_tokens_qa = gr.Slider(
                            128, 1024, value=512, step=64,
                            label="Tokens de g√©n√©ration"
                        )
                        temperature_qa = gr.Slider(
                            0.1, 1.0, value=0.7, step=0.1,
                            label="Temp√©rature"
                        )
                    
                    ask_btn = gr.Button("‚ùì Demander", variant="primary", size="lg")
                
                with gr.Column(scale=2):
                    gr.Markdown("### üìä R√©ponse")
                    
                    with gr.Tabs():
                        with gr.Tab("üìö Sources"):
                            sources_output_qa = gr.Textbox(
                                label="Sources m√©dicales",
                                lines=12,
                                max_lines=25,
                                elem_classes=["output-text"]
                            )
                        
                        with gr.Tab("üí° R√©ponse"):
                            answer_output_qa = gr.Textbox(
                                label="R√©ponse d√©taill√©e",
                                lines=12,
                                max_lines=25,
                                elem_classes=["output-text"]
                            )
            
            ask_btn.click(
                fn=answer_question,
                inputs=[
                    question_input,
                    use_rag_qa,
                    num_sources_qa,
                    max_tokens_qa,
                    temperature_qa
                ],
                outputs=[sources_output_qa, answer_output_qa]
            )
    
    gr.Markdown("""
    ---
    ### üéØ Instructions:
    
    **Analyse de Sympt√¥mes:**
    1. D√©crivez les sympt√¥mes observ√©s (l√©sion, couleur, forme, etc.)
    2. Indiquez la dur√©e
    3. Activez RAG pour une analyse bas√©e sur la litt√©rature
    4. Cliquez sur "Analyser"
    
    **Questions G√©n√©rales:**
    1. Posez une question sur un sujet dermatologique
    2. Activez RAG pour des r√©ponses citant la litt√©rature
    3. Cliquez sur "Demander"
    
    ### ‚ö° Note:
    Le premier lancement prend ~1-2 minutes (chargement des mod√®les).
    Les rapports sont sauvegard√©s automatiquement (analysis_YYYYMMDD_HHMMSS.txt).
    """)


# ============================================================================
# Lancement
# ============================================================================

if __name__ == "__main__":
    gradio_config = config.get('gradio', {})
    
    logger.info("="*80)
    logger.info("üöÄ Lancement de LLM-Bot Gradio App")
    logger.info("="*80)
    logger.info(f"   Port: {gradio_config.get('port', 7861)}")
    logger.info(f"   Share: {gradio_config.get('share', False)}")
    logger.info("="*80)
    
    demo.launch(
        server_name=gradio_config.get('server_name', '0.0.0.0'),
        server_port=gradio_config.get('port', 7861),
        share=gradio_config.get('share', False),
        debug=True,
        show_error=True
    )
